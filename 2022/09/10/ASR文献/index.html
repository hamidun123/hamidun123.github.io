<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hamidun123.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":{"gitalk":{"order":-1}},"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="整理ASR相关文献">
<meta property="og:type" content="article">
<meta property="og:title" content="ASR文献">
<meta property="og:url" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/index.html">
<meta property="og:site_name" content="宇坤の博客">
<meta property="og:description" content="整理ASR相关文献">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20220217095143475.png">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20220222102925728.png">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20211119160633080.png">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20211119163056593.png">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20211119162801227.png">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20211122141950209.png">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20211122164521127.png">
<meta property="og:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20211123101323894.png">
<meta property="article:published_time" content="2022-09-10T12:58:03.000Z">
<meta property="article:modified_time" content="2023-01-12T13:04:13.601Z">
<meta property="article:author" content="Yukun Qian">
<meta property="article:tag" content="ASR">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/img/image-20220217095143475.png">


<link rel="canonical" href="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/","path":"2022/09/10/ASR文献/","title":"ASR文献"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ASR文献 | 宇坤の博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">宇坤の博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#asr"><span class="nav-number">1.</span> <span class="nav-text">ASR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#a-re-thinking-asr-modeling-framework-using-attention-mechanisms"><span class="nav-number">1.1.</span> <span class="nav-text">1.《A
Re-thinking ASR Modeling Framework using Attention Mechanisms》</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#specaugment-a-simple-data-augmentation-method-for-automatic-speech-recognition"><span class="nav-number">1.2.</span> <span class="nav-text">2.《SpecAugment:
A Simple Data Augmentation Method for Automatic Speech
Recognition》</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#asr%E9%9D%9E%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">ASR非自回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#spike-triggered-non-autoregressive-transformer-for-end-to-end-speech-recognition"><span class="nav-number">2.1.</span> <span class="nav-text">1.《Spike-Triggered
Non-Autoregressive Transformer for End-to-End Speech Recognition》</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#non-autoregressive-transformer-for-speech-recognition"><span class="nav-number">2.2.</span> <span class="nav-text">2.《Non-Autoregressive
Transformer for Speech Recognition》</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#listen-attentively-and-spell-once-whole-sentence-generation-via-a-non-autoregressive-architecture-for-low-latency-speech-recognition"><span class="nav-number">2.3.</span> <span class="nav-text">3.《Listen
Attentively, and Spell Once: Whole Sentence Generation via a
Non-Autoregressive Architecture for Low-Latency Speech
Recognition》</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yukun Qian"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Yukun Qian</p>
  <div class="site-description" itemprop="description">科研记录</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hamidun123" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hamidun123" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:qianyukun123@foxmail.com" title="E-Mail → mailto:qianyukun123@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Yukun Qian">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宇坤の博客">
      <meta itemprop="description" content="科研记录">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ASR文献 | 宇坤の博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ASR文献
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-09-10 20:58:03" itemprop="dateCreated datePublished" datetime="2022-09-10T20:58:03+08:00">2022-09-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-01-12 21:04:13" itemprop="dateModified" datetime="2023-01-12T21:04:13+08:00">2023-01-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%96%87%E7%8C%AE%E5%BD%92%E7%BA%B3/" itemprop="url" rel="index"><span itemprop="name">文献归纳</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>整理ASR相关文献</p>
<span id="more"></span>
<h2 id="asr">ASR</h2>
<h3
id="a-re-thinking-asr-modeling-framework-using-attention-mechanisms">1.《A
Re-thinking ASR Modeling Framework using Attention Mechanisms》</h3>
<p>Chih-Ying Yang and Kuan-Yu Chen</p>
<p>作者使用注意力机制来改进 <strong>ASR</strong></p>
<p>作者提出的模型名为 <strong>re-thinking
ASR</strong>（<strong>rt-ASR</strong>）</p>
<figure>
<img src="img\image-20220217095143475.png"
alt="image-20220217095143475" />
<figcaption aria-hidden="true">image-20220217095143475</figcaption>
</figure>
<p>作者的模型之所以叫 <strong>re-thinking ASR</strong>
是因为它对假设的语言规律进行了计算，作者是希望通过重新思考假设的语言规律以及文本和声学特征来产生更准确的识别结果</p>
<p>其主要包括 <strong>Encoder</strong> 和 <strong>Decoder</strong>
两部分，其中 <strong>Decoder</strong> 部分使用的是 <strong>modified
Transformer</strong>，其具有 <strong>mixed attention</strong> 和
<strong>self-and-mixed attention</strong></p>
<p>假设语音序列为 <span
class="math inline">\(X=\{x_1,\dots,x_T\}\)</span> 对应的文本序列为
<span class="math inline">\(Y=\{y_1,\dots,y_L\}\)</span></p>
<p>在 <strong>特征提取</strong> 部分作者使用两层 <strong>CNN</strong>
来获取语音特征，并设置步长为2，从而使得特征数减少到 <span
class="math inline">\(\frac{1}{4}T\)</span> ,接下来引入位置编码，并通过
<strong>N</strong> 层 <strong>Transformer</strong> 得到语音的编码特征
<span
class="math inline">\(H^\alpha=\{h^{\alpha}_1,\dots,h^{\alpha}_{T/4}\}\)</span></p>
<p>在解码器部分作者想的是尽可能利用多模态信息，其输入是 <span
class="math inline">\(\{Y^f,Y^s_{1:(m-1)}\}\)</span>，其中 <span
class="math inline">\(Y^f=\{y^f_1,\dots,y^f_{L&#39;}\}\)</span>，是由
<strong>ASR 假设（First Pass ASR）</strong> 得到的预测解码序列，而 <span
class="math inline">\(Y^s_{1:(m-1)}=\{y^s_1,\dots,y^s_{m-1}\}\)</span>则是
<strong>rt-ASR</strong>
模型的输出，两个部分分别加上位置编码和段落编码，送入
<strong>Decoder</strong></p>
<p>在 <strong>mixed attention</strong> 部分 <span
class="math display">\[
Q_{mixed}=Y^s_{1:(m-1)}W^Q_{mixed}
\\K_{mixed}=[Y^f;Y^s_{1:(m-1)}]W^K_{mixed}
\\V_{mixed}=[Y^f;Y^s_{1:(m-1)}]W^V_{mixed}
\\
\overline{Y}^s_{1:(m-1)}=softmax(\frac{Q_{mixed}(K_{mixed})^T}{\sqrt{d}})V_{mixed}
\]</span> 这里生成的 <span
class="math inline">\(\overline{Y}^s_{1:(m-1)}\)</span>
还拥有了未来的信息（由于 <strong>First Pass ASR</strong>）</p>
<p>接下来利用 <strong>self-and-mixed attention</strong>
来混合文本和声音信息，这一步除了利用 <span
class="math inline">\(H^\alpha\)</span> 和 <span
class="math inline">\(\overline{Y}^s_{1:(m-1)}\)</span> 得到 <span
class="math inline">\(\overline{\overline{Y}}^s_{1:(m-1)}\)</span>
以外，还计算了 <span class="math inline">\(H^\alpha\)</span>
的自我注意力 <span
class="math inline">\(\overline{H}^\alpha\)</span></p>
<p>作者实验了两种 <strong>First Pass ASR</strong> 模型，发现都有
<strong>3%</strong> 左右的提高</p>
<figure>
<img
src="C:\Users\QYK\AppData\Roaming\Typora\typora-user-images\image-20220217110237148.png"
alt="image-20220217110237148" />
<figcaption aria-hidden="true">image-20220217110237148</figcaption>
</figure>
<h3
id="specaugment-a-simple-data-augmentation-method-for-automatic-speech-recognition">2.《SpecAugment:
A Simple Data Augmentation Method for Automatic Speech
Recognition》</h3>
<p>Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret
Zoph, Ekin D. Cubuk, Quoc V. Le</p>
<p>作者提出了一种简单的用于 <strong>ASR</strong> 的数据增强的方法
<strong>SpecAugment</strong></p>
<p>作者提出的直接作用于 <strong>mel</strong> 频谱</p>
<p>主要有三种方法，<strong>Time warping、Frequency masking、Time
masking</strong></p>
<p><strong>Time warping</strong>
是指将图像除边界点外部分进行折叠，产生的效果类似水平平移</p>
<p><strong>Frequency masking</strong> 则是在屏蔽某一特定宽度的频率值</p>
<p><strong>Time masking</strong> 是屏蔽某一特定宽度的时间值</p>
<figure>
<img src="img\image-20220222102925728.png"
alt="image-20220222102925728" />
<figcaption aria-hidden="true">image-20220222102925728</figcaption>
</figure>
<h2 id="asr非自回归模型">ASR非自回归模型</h2>
<p>目前的大部分序列到序列模型都是自回归模型，即利用上一解码步骤的结果来预测当前时间步的结果，但这样的自回归性质会导致在inference时出现很大的延迟，而非自回归模型则可以摆脱这种依赖，提高推理速度</p>
<h3
id="spike-triggered-non-autoregressive-transformer-for-end-to-end-speech-recognition">1.《Spike-Triggered
Non-Autoregressive Transformer for End-to-End Speech Recognition》</h3>
<p>中科院自动化所的文章 Zhengkun Tian, Jiangyan Yi, Jianhua Tao, Ye Bai,
Shuai Zhang, Zhengqi Wen</p>
<p>文章提出了讲非自回归网络应用到语音识别上</p>
<p>具体使用的是 <strong>Non-Autoregressive
Transformer（NAT）</strong>。一般的 <strong>NAT</strong>
会采用固定的长度的掩码序列来作为输入，从而预测目标序列。因此该固定长度对模型性能有很大的影响，目前主要的方法有
1. 引入神经网络来预测目标长度，但该方法需要对不同长度像本进行采样。2.
设定固定长度，由于为了确保模型性能，长度往往会比目标序列长很多。3. 利用
<strong>CTC</strong>
损失代替交叉熵损失函数，但在inference时会生成重复标记和空白并不会提高infernece速度</p>
<p>因此作者提出了 <strong>Spike-Triggered Non-Autoregressive
Transformer（ST-NAT）</strong></p>
<figure>
<img src="img/image-20211119160633080.png"
alt="image-20211119160633080" />
<figcaption aria-hidden="true">image-20211119160633080</figcaption>
</figure>
<p>其主要由编码器，解码器，CTC组成，其中的编码器和解码器和Transformer类似</p>
<p>首先对输入的语音序列进行卷积和添加位置信息，之后送入到编码器</p>
<p>文章的主要创新点在引入CTC峰值模块对目标序列长度进行预测，将编码器的输出输入到CTC网络中，当CTC输出高过阈值之后记录触发阈值来估计长度</p>
<p>随后做实验证明了CTC可以准确预测长度，并且也可以正确触发</p>
<figure>
<img src="img/image-20211119163056593.png"
alt="image-20211119163056593" />
<figcaption aria-hidden="true">image-20211119163056593</figcaption>
</figure>
<figure>
<img src="img/image-20211119162801227.png"
alt="image-20211119162801227" />
<figcaption aria-hidden="true">image-20211119162801227</figcaption>
</figure>
<h3
id="non-autoregressive-transformer-for-speech-recognition">2.《Non-Autoregressive
Transformer for Speech Recognition》</h3>
<p>Nanxin Chen，Shinji Watanabe，Jesús Villalba，Najim Dehak</p>
<p>作者提出了两种非自回归模型：A-CMLM，A-FMLM</p>
<p>目前深层Transformer已经在ASR上得到了很好的应用，但是由于其是自回归模型，在推理阶段会很难并行，消耗大量计算量</p>
<p>因此作者提出使用非自回归模型，并支持目前在ASR领域的
<strong>Non-Autoregressive</strong> 普遍依赖于 <strong>CTC</strong>
，作者的灵感来自于 <strong>CMLM</strong></p>
<p><img src="img/image-20211122141950209.png" /></p>
<p>在传统的 <strong>ASR</strong>
方面解码器根据之前的解码结果生成当前时间步骤的解码 <span
class="math display">\[
P(y_l|y_{&lt;l},x)=P_{dec}(y_l|y_{&lt;l},f_l(h))
\]</span> 在训练阶段，可以通过给予正确的输入以达到并行解码，但在
<strong>inference</strong> 的时候则需要一步步解码</p>
<p>目前使用 <strong>Non-Autoregressive</strong> 有两种方法 一种是基于
<strong>CTC</strong> 的方法，另一种则是多次迭代来完成预测</p>
<p>作者提出的是 <strong>Audio-Conditional Masked Language Model
(A-CMLM)</strong> 其思想是从以前结算中得到的部分替代自回归模型中的 <span
class="math inline">\(y_{&lt;l}\)</span> 在模型中引入了
<strong>[MASK]</strong> 标签，这里用<span
class="math inline">\(L_M\)</span>和<span
class="math inline">\(L_U\)</span>来表示被 <strong>MASK</strong>
的部分和未被 <strong>MASK</strong> 的部分 <span class="math display">\[
P(y_{L_M}|y_{L_U},x)=\prod_{l\in l_M}P_{dec}(y_l|y_{L_U},f_l(h))
\]</span> 其过程如上图第二部分所示，在训练阶段随机 <strong>MASK</strong>
部分，然后要求模型根据输入去预测这些被 <strong>MASK</strong>
的部分，这里作者假设了预测被 <strong>MASK</strong>
的部分之间是互相独立的，因此才可以实现概率上的相乘</p>
<p>同时作者在 <strong>A-CMLM</strong> 的基础上提出了改进后的
<strong>Audio-Factorized Masked Language Model (A-FMLM)</strong>
，由于在 <strong>A-CMLM</strong> 中训练和 <strong>inference</strong>
步骤之间还是存在一定差距，<strong>inference</strong>
要求初始输入全部都是被 <strong>MASK</strong> 的，而
<strong>A-CMLM</strong> 训练中还是需要有部分未被
<strong>MASK</strong>的存在。为了缓解这种问题，作者提出了
<strong>A-FMLM</strong></p>
<p>作者假设输出长度为 <span class="math inline">\(L\)</span>，迭代次数为
<span class="math inline">\(K\)</span> <span class="math display">\[
Z_0=\phi
\\ Z_K=[0,1,\dots,L-1]
\\ \forall i \ \ Z_i\subset Z_{i+1}
\]</span> 这样训练和推理过程都可以变为： <span class="math display">\[
P(y|h)=\prod^{K}_{i=1}\prod_{l\in Z_i\cap
\overline{Z}_{i-1}}P_{dec}(y_L|y_{Z_{i-1}},f_l(h))
\]</span> 这样定义以后，自回归模型就变成了 <span
class="math inline">\(K=L,Z_i=[0,1,\dots,i-1]\)</span> 的一种特例</p>
<p>在推理过程中，使用了 <strong>easy decoding</strong>
在第一次预测的时候先预测最可靠的标记，之后根据该结果进行后面的迭代</p>
<p><img src="img/image-20211122164521127.png" /></p>
<h3
id="listen-attentively-and-spell-once-whole-sentence-generation-via-a-non-autoregressive-architecture-for-low-latency-speech-recognition">3.《Listen
Attentively, and Spell Once: Whole Sentence Generation via a
Non-Autoregressive Architecture for Low-Latency Speech
Recognition》</h3>
<p>中科院自动化所 Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengkun Tian,
Zhengqi Wen, Shuai Zhang</p>
<p>作者指出上一篇文章中提到的模型存在着仍然需要解码器多路前向传播来完成所有的
<strong>[MASK]</strong> 预测</p>
<p>作者认为可以通过提取语义，在不依赖显式语言模型的情况下生成标记序列，为此作者提出了
<strong>LASO (Listen Attentively, and Spell Once)</strong></p>
<figure>
<img src="img/image-20211123101323894.png"
alt="image-20211123101323894" />
<figcaption aria-hidden="true">image-20211123101323894</figcaption>
</figure>
<p>作者认为可以从声音序列中提取出语言语义表示（这里指的是标签之前的关系），基于此作者定义基于位置的
<strong>token</strong> 预测为 <span class="math display">\[
z=Encoder(x)
\\ P(y_i|x)=SummarizeAndDecode(z),\ \ i=1,2,\dots,L
\]</span> 其中 <span class="math inline">\(z_i\)</span>
是经过编码器表示后的隐藏表示序列</p>
<p><strong>LASO</strong> 主要由三个部分组成，编码器，position dependent
summarizer（PDS），解码器</p>
<p>其中 <strong>PDS</strong> 负责将编码器输出总结为
<strong>token</strong> 级别的表示，解码器则在每个位置生成
<strong>token</strong></p>
<p>编码器部分和常见的 <strong>ASR Transformer</strong> 编码器一致</p>
<p>作者认为文本是高度压缩的语义表示，多个声学特征才能对应一个文本标记，为此作者设计了
<strong>PDS</strong> 来总结编码器表示，并根据token位置来重新组织</p>
<p>在 <strong>PDS</strong> 中有两个注意力部分，第一部分的
<strong>Queries</strong> 是最大长度 <strong>L</strong>
的位置编码，第二部分的 <strong>Queries</strong>
是上一部分的输出，两部分的 <strong>Keys</strong> 和
<strong>Values</strong> 都是编码器提供的，作者使用的是正弦函数来编码位置
<span class="math display">\[
pe_{i,2j}=sin(i/10000^{2j/D_m})
\\ pe_{i,2j+1}=cos(i/10000^{2j/D_m})
\]</span></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>Buy me a coffee</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.jpg" alt="Yukun Qian 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.jpg" alt="Yukun Qian 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Yukun Qian
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://hamidun123.github.io/2022/09/10/ASR%E6%96%87%E7%8C%AE/" title="ASR文献">https://hamidun123.github.io/2022/09/10/ASR文献/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/ASR/" rel="tag"># ASR</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/09/10/Streaming%20ASR/" rel="prev" title="Streaming ASR">
                  <i class="fa fa-chevron-left"></i> Streaming ASR
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/09/10/SLU%E6%96%87%E7%8C%AE/" rel="next" title="SLU文献">
                  SLU文献 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2021 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yukun Qian</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/hamidun123" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"hamidun123","repo":"hamidun123.github.io","client_id":"843ef81eb1a845e082a7","client_secret":"3fcace7a38908d390ad486440c7e6e3f9bf19a6a","admin_user":"hamidun123","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"2ac36b5247d568e481f2b9db71fac3e9"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
